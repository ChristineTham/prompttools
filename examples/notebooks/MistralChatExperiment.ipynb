{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a13ddc8",
   "metadata": {},
   "source": [
    "# Mistral Chat Experiment Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623f0cfe",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "885dabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet --force-reinstall prompttools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac35f8",
   "metadata": {},
   "source": [
    "## Setup imports and API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edba05a",
   "metadata": {},
   "source": [
    "First, we'll need to set our API keys. If we are in DEBUG mode, we don't need to use a real OpenAI key, so for now we'll set them to empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed4e635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MISTRAL_API_KEY\"] = \"\"  # Insert your key here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "155d2fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "\n",
    "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "model = \"mistral-tiny\"\n",
    "\n",
    "client = MistralClient(api_key=api_key)\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(role=\"user\", content=\"What is the best French cheese?\")\n",
    "]\n",
    "\n",
    "# No streaming\n",
    "chat_response = client.chat(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5f86d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Determining the \"best\" French cheese is subjective as it depends on personal preferences. Some popular and highly regarded French cheeses include:\\n\\n1. Roquefort: A blue-veined cheese made from sheep\\'s milk. It is known for its strong, pungent, and tangy flavor.\\n2. Camembert: A soft, creamy cheese with a white rind and a rich, earthy taste. It is one of the most famous French cheeses.\\n3. Comté: A nutty, firm, and slightly sweet cheese made from unpasteurized cow\\'s milk. It is often compared to Swiss Emmenthal.\\n4. Brie de Meaux: A soft, creamy cheese with a white rind and a mild, buttery taste. It is considered the original Brie.\\n5. Munster: A smelly, soft, and runny cheese with a pungent aroma and a strong, savory flavor.\\n6. Reblochon: A soft, creamy cheese with a bloomy rind and a rich, milky, and slightly sweet taste.\\n7. Époisses: A strong-smelling, soft, and runny cheese with a pungent flavor and a velvety texture.\\n\\nEach of these cheeses has its unique characteristics and flavor profile, so it\\'s essential to try them to determine which one suits your taste preferences the best.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c8a211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44170e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "842f1e47",
   "metadata": {},
   "source": [
    "Then we'll import the relevant `prompttools` modules to setup our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beaa70a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompttools.experiment import MistralChatCompletionExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622dea9a",
   "metadata": {},
   "source": [
    "## Run an experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3babfe5a",
   "metadata": {},
   "source": [
    "Next, we create our test inputs. We can iterate over models, inputs, and configurations like temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9114cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "models = [\"mistral-tiny\"]\n",
    "messages = [\n",
    "    ChatMessage(role=\"system\", content=\"You are a helpful assistant.\"),\n",
    "    ChatMessage(role=\"user\", content=\"Who was the first president?\"),\n",
    "]\n",
    "temperatures = [0.0, 1.0]\n",
    "# You can add more parameters that you'd like to test here.\n",
    "\n",
    "experiment = MistralChatCompletionExperiment(models, messages, temperature=temperatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa5450",
   "metadata": {},
   "source": [
    "We can then run the experiment to get results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b33130",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7598332b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>messages</th>\n",
       "      <th>temperature</th>\n",
       "      <th>response</th>\n",
       "      <th>response_usage</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Who was the first president?'}]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>{'completion_tokens': 18, 'prompt_tokens': 57, 'total_tokens': 75}</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Who was the first president?'}]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>{'completion_tokens': 18, 'prompt_tokens': 57, 'total_tokens': 75}</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Who was the first president?'}]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>{'completion_tokens': 18, 'prompt_tokens': 57, 'total_tokens': 75}</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Who was the first president?'}]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>{'completion_tokens': 18, 'prompt_tokens': 57, 'total_tokens': 75}</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  \\\n",
       "0  gpt-3.5-turbo        \n",
       "1  gpt-3.5-turbo        \n",
       "2  gpt-3.5-turbo-0613   \n",
       "3  gpt-3.5-turbo-0613   \n",
       "\n",
       "                                                                                                                       messages  \\\n",
       "0  [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Who was the first president?'}]   \n",
       "1  [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Who was the first president?'}]   \n",
       "2  [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Who was the first president?'}]   \n",
       "3  [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Who was the first president?'}]   \n",
       "\n",
       "   temperature           response  \\\n",
       "0  0.0          George Washington   \n",
       "1  1.0          George Washington   \n",
       "2  0.0          George Washington   \n",
       "3  1.0          George Washington   \n",
       "\n",
       "                                                       response_usage  \\\n",
       "0  {'completion_tokens': 18, 'prompt_tokens': 57, 'total_tokens': 75}   \n",
       "1  {'completion_tokens': 18, 'prompt_tokens': 57, 'total_tokens': 75}   \n",
       "2  {'completion_tokens': 18, 'prompt_tokens': 57, 'total_tokens': 75}   \n",
       "3  {'completion_tokens': 18, 'prompt_tokens': 57, 'total_tokens': 75}   \n",
       "\n",
       "    latency  \n",
       "0  0.000006  \n",
       "1  0.000005  \n",
       "2  0.000003  \n",
       "3  0.000002  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266c13eb",
   "metadata": {},
   "source": [
    "## Evaluate the model response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb8023",
   "metadata": {},
   "source": [
    "To evaluate the results, we'll define an eval function. We can use semantic distance to check if the model's response is similar to our expected output.\n",
    "\n",
    "Since we are using semantic similarity, you need to have the library `sentence_transformers` installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c0c9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
